{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "os.chdir(\"c:/Users/Robert/Documents/Projekte/dev/sport_betting/\")\n",
    "import config as CONFIG\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.provide_data import get_model_data\n",
    "from src.models.evaluate import custom_classification_report, custom_lazy_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 5246\n",
      "Valid 1952\n",
      "Test 1952\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_model_data(filename = \"Train\")\n",
    "X_valid, y_valid = get_model_data(filename = \"Valid\")\n",
    "X_test, y_test = get_model_data(filename = \"Test\")\n",
    "\n",
    "cat = [X_train.columns.get_loc(i) for i in [\"Team\",\"Div\",\"Opponent\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bets(y,X,columns=['BW_Team','BW_Draw','BW_Opponent']):\n",
    "    y_bets = pd.concat([y,X[columns]],axis=1)\n",
    "    return y_bets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bets = np.array(add_bets(y=y_train,X=X_train,columns=['BW_Team','BW_Draw','BW_Opponent']))\n",
    "y_test_bets = np.array(add_bets(y=y_test,X=X_test,columns=['BW_Team','BW_Draw','BW_Opponent']))\n",
    "y_valid_bets = np.array(add_bets(y=y_valid,X=X_valid,columns=['BW_Team','BW_Draw','BW_Opponent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale training and test data\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB(alpha=10,binarize=0.5)\n",
    "bnb.fit(X_train,y=y_train)\n",
    "y_pred = bnb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_column_indices(df, column_names):\n",
    "    \"\"\"\n",
    "    Returns the indices of the given column names within the dataframe.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): the dataframe\n",
    "    - column_names (list of str): the names of the columns to get indices for\n",
    "    \n",
    "    Returns:\n",
    "    - indices (list of int): the indices of the columns within the dataframe\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for col_name in column_names:\n",
    "        try:\n",
    "            indices.append(df.columns.get_loc(col_name))\n",
    "        except KeyError:\n",
    "            print(f\"Column name '{col_name}' not found in dataframe.\")\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind  = get_column_indices(df = pd.DataFrame(X_valid,columns=features), column_names = [\"B365_Team\",\"B365_Draw\",\"B365_Opponent\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "# Define pretrainer model architecture\n",
    "pretrainer = TabNetPretrainer(\n",
    "optimizer_fn=torch.optim.Adam,\n",
    "optimizer_params=dict(lr=2e-2),\n",
    "mask_type=\"entmax\"\n",
    ")\n",
    "\n",
    "# Train pretrainer model on training data\n",
    "pretrainer.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_valid],\n",
    "    max_epochs=1000,\n",
    "    patience=30,\n",
    "    pretraining_ratio=0.8,\n",
    "    batch_size= 64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import save_as_pickle\n",
    "\n",
    "save_as_pickle(pretrainer,'pretrainer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_from_pickle' from 'src.utils.utils' (c:\\Users\\Robert\\Documents\\Projekte\\dev\\sport_betting\\src\\utils\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_53824\\3449190334.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_from_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_from_pickle' from 'src.utils.utils' (c:\\Users\\Robert\\Documents\\Projekte\\dev\\sport_betting\\src\\utils\\utils.py)"
     ]
    }
   ],
   "source": [
    "from src.utils.utils import load_from_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import load_from_pickle\n",
    "\n",
    "load_from_pickle(CONFIG.DATA_FOLDER_MODELS+'pretrainer.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LossFunction TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.loss_function import PrecisionLoss, TotalValueLoss\n",
    "\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "n_d = 8\n",
    "n_a = 8\n",
    "n_steps = 3\n",
    "gamma = 1\n",
    "lambda_sparse = 0.001\n",
    "lr = 2e-2\n",
    "batch_size = 128\n",
    "max_epochs = 1000\n",
    "# Define a custom loss function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = TabNetClassifier(n_d=n_d, n_a=n_a, n_steps=n_steps, gamma=gamma, lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=lr), mask_type='entmax', device_name='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define and train the model with the custom loss function\n",
    "model.fit(X_train=X_train, y_train=y_train,     eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'], eval_metric=['balanced_accuracy','auc'],batch_size=batch_size, max_epochs=max_epochs, patience=50,loss_fn=TotalValueLoss(),from_unsupervised=pretrainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Metric TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from typing import List\n",
    "\n",
    "class Precision(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"precision\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true: List[int], y_pred: List[int]):\n",
    "        precision = precision_score(y_true, y_pred[:,1]>0.5)\n",
    "        return precision\n",
    "\n",
    "model.fit(X_train=X_train, y_train=y_train,  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],eval_metric=['auc',Precision],batch_size=batch_size, max_epochs=max_epochs, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "n_d = 8\n",
    "n_a = 8\n",
    "n_steps = 3\n",
    "gamma = 1\n",
    "lambda_sparse = 0.001\n",
    "lr = 2e-2\n",
    "batch_size = 128\n",
    "max_epochs = 1000\n",
    "# Define a custom loss function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "class BetLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        if len(output.shape)>1:\n",
    "            output_array =  torch.clamp(torch.abs(output[:,1]),min=0, max=1)\n",
    "        else:\n",
    "            output_array = output\n",
    "        output_array = torch.clamp(torch.abs(output[:,1]),min=0, max=1)            \n",
    "\n",
    "        if len(target.shape)>1:\n",
    "            target_array = target[:,0]\n",
    "        else:\n",
    "            target_array = target\n",
    "        target_array = torch.clamp(torch.abs(target_array),min=0, max=1)      \n",
    "        #self.bets\n",
    "        output_array = output_array>0.5\n",
    "        target_array = target_array>0.5\n",
    "        # loss = torch.sum(torch.abs(self.X_train_subset) * (torch.abs(target)-torch.abs(output)))/ torch.sum(torch.abs(self.X_train_subset))\n",
    "        # precision = torch.sum((output_array == True) & (target_array == True))/target_array.size(0)\n",
    "        loss = torch.sum(1/output_array[(output_array > 0.5) & (target_array != True)])/torch.sum(1/output_array[(output_array > 0.5)])\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    \n",
    "ind = [i for i, x in enumerate(features) if x in [\"BW_Team\"]]\n",
    "\n",
    "model = TabNetClassifier(n_d=n_d, n_a=n_a, n_steps=n_steps, gamma=gamma, lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=lr), mask_type='entmax', device_name='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define and train the model with the custom loss function\n",
    "# Define and train the model with the custom loss function\n",
    "model.fit(X_train=X_train, y_train=y_train,  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid',\"precision\"], eval_metric=['balanced_accuracy','auc',Precision],batch_size=batch_size, max_epochs=max_epochs, patience=50,loss_fn=BetLoss())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "clf = model\n",
    "#plt.plot(clf.history['loss'], label='Validation Loss')\n",
    "plt.plot(clf.history['valid_auc'], label='AUC')\n",
    "plt.plot(clf.history['valid_balanced_accuracy'], label='Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "r = classification_report(y_pred=y_pred,y_true=y_test)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test_bets[:,1][y_pred&y_test])-sum(y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erklärbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f_i = np.round(pd.Series(clf.feature_importances_),3)\n",
    "f_i.index = features\n",
    "f_i = f_i.sort_values(ascending=False)\n",
    "print(f_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"BW_opponent_odd_pred\",\"B365_Opponent\",\"Avg_Opponent\",\"IW_Team\",\"Span_Draw\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(f_i>0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
