{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "os.chdir(\"c:/Users/Robert/Documents/Projekte/dev/sport_betting/\")\n",
    "import config as CONFIG\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.data.provide_data import get_model_data\n",
    "from src.models.evaluate import custom_classification_report, custom_lazy_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/model_data_deployment.csv\",index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set'] = \"train\"\n",
    "df.loc[df.year > 2020, 'set'] = \"valid\"\n",
    "df.loc[df.year > 2022, 'set'] = \"test\"\n",
    "\n",
    "df = df.drop([\"B365_Opponent\",\"B365_Draw\",\"B365_Team\",'B365_Team_odd_pred', 'B365_opponent_odd_pred', 'B365_Team_draw_pred'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atHome</th>\n",
       "      <th>Div</th>\n",
       "      <th>Target</th>\n",
       "      <th>BW_Opponent</th>\n",
       "      <th>BW_Draw</th>\n",
       "      <th>BW_Team</th>\n",
       "      <th>IW_Opponent</th>\n",
       "      <th>IW_Draw</th>\n",
       "      <th>IW_Team</th>\n",
       "      <th>Team</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Max_Team</th>\n",
       "      <th>Min_Team</th>\n",
       "      <th>Avg_Team</th>\n",
       "      <th>Span_Team</th>\n",
       "      <th>Ratio_Team</th>\n",
       "      <th>Max_Opponent</th>\n",
       "      <th>Min_Opponent</th>\n",
       "      <th>Avg_Opponent</th>\n",
       "      <th>Span_Opponent</th>\n",
       "      <th>Ratio_Opponent</th>\n",
       "      <th>Max_Draw</th>\n",
       "      <th>Min_Draw</th>\n",
       "      <th>Avg_Draw</th>\n",
       "      <th>Span_Draw</th>\n",
       "      <th>Ratio_Draw</th>\n",
       "      <th>IW_Team_odd_pred</th>\n",
       "      <th>IW_opponent_odd_pred</th>\n",
       "      <th>IW_Team_draw_pred</th>\n",
       "      <th>BW_Team_odd_pred</th>\n",
       "      <th>BW_opponent_odd_pred</th>\n",
       "      <th>BW_Team_draw_pred</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>SP2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.55</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.60</td>\n",
       "      <td>Santander</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.011538</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.039216</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.065574</td>\n",
       "      <td>0.313253</td>\n",
       "      <td>0.319277</td>\n",
       "      <td>0.367470</td>\n",
       "      <td>0.315152</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.375758</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>SP2</td>\n",
       "      <td>False</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Sp Gijon</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.202778</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>0.223464</td>\n",
       "      <td>0.407821</td>\n",
       "      <td>0.368715</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>0.382022</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>SP1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.30</td>\n",
       "      <td>Almeria</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.483333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>0.259887</td>\n",
       "      <td>0.350282</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>SP1</td>\n",
       "      <td>False</td>\n",
       "      <td>9.75</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1.33</td>\n",
       "      <td>Ath Bilbao</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.316667</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.023077</td>\n",
       "      <td>11.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.084018</td>\n",
       "      <td>0.568541</td>\n",
       "      <td>0.347442</td>\n",
       "      <td>0.080882</td>\n",
       "      <td>0.597426</td>\n",
       "      <td>0.321691</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>SP1</td>\n",
       "      <td>True</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.10</td>\n",
       "      <td>Ath Madrid</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.029412</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.226519</td>\n",
       "      <td>0.397790</td>\n",
       "      <td>0.375691</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atHome  Div  Target  BW_Opponent  BW_Draw  BW_Team  IW_Opponent  IW_Draw  \\\n",
       "0    True  SP2    True         2.55     3.10     2.60         2.65     3.05   \n",
       "1    True  SP2   False         3.60     3.40     1.90         3.65     3.30   \n",
       "2    True  SP1   False         3.00     3.60     2.25         3.10     3.45   \n",
       "3    True  SP1   False         9.75     5.25     1.32         9.00     5.50   \n",
       "4    True  SP1    True         3.60     3.40     2.05         3.60     3.45   \n",
       "\n",
       "   IW_Team        Team  month  year  Max_Team  Min_Team  Avg_Team  Span_Team  \\\n",
       "0     2.60   Santander      5  2023      2.63      2.60  2.610000       0.03   \n",
       "1     2.00    Sp Gijon      5  2023      2.00      1.85  1.916667       0.15   \n",
       "2     2.30     Almeria      5  2023      2.30      2.25  2.266667       0.05   \n",
       "3     1.33  Ath Bilbao      5  2023      1.33      1.30  1.316667       0.03   \n",
       "4     2.10  Ath Madrid      5  2023      2.10      2.00  2.050000       0.10   \n",
       "\n",
       "   Ratio_Team  Max_Opponent  Min_Opponent  Avg_Opponent  Span_Opponent  \\\n",
       "0    1.011538          2.65          2.55      2.610000           0.10   \n",
       "1    1.081081          4.33          3.60      3.860000           0.73   \n",
       "2    1.022222          3.10          3.00      3.066667           0.10   \n",
       "3    1.023077         11.00          9.00      9.916667           2.00   \n",
       "4    1.050000          3.60          3.60      3.600000           0.00   \n",
       "\n",
       "   Ratio_Opponent  Max_Draw  Min_Draw  Avg_Draw  Span_Draw  Ratio_Draw  \\\n",
       "0        1.039216      3.25      3.05  3.133333        0.2    1.065574   \n",
       "1        1.202778      3.40      3.30  3.366667        0.1    1.030303   \n",
       "2        1.033333      3.60      3.40  3.483333        0.2    1.058824   \n",
       "3        1.222222      5.50      5.00  5.250000        0.5    1.100000   \n",
       "4        1.000000      3.50      3.40  3.450000        0.1    1.029412   \n",
       "\n",
       "   IW_Team_odd_pred  IW_opponent_odd_pred  IW_Team_draw_pred  \\\n",
       "0          0.313253              0.319277           0.367470   \n",
       "1          0.223464              0.407821           0.368715   \n",
       "2          0.259887              0.350282           0.389831   \n",
       "3          0.084018              0.568541           0.347442   \n",
       "4          0.229508              0.393443           0.377049   \n",
       "\n",
       "   BW_Team_odd_pred  BW_opponent_odd_pred  BW_Team_draw_pred   set  \n",
       "0          0.315152              0.309091           0.375758  test  \n",
       "1          0.213483              0.404494           0.382022  test  \n",
       "2          0.254237              0.338983           0.406780  test  \n",
       "3          0.080882              0.597426           0.321691  test  \n",
       "4          0.226519              0.397790           0.375691  test  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['set'] == 'train']\n",
    "train_df.drop('set',axis=1).to_csv(CONFIG.DATA_FOLDER_PROCESSED+\"train/model_data.csv\")\n",
    "\n",
    "valid_df = df[df['set'] == 'valid']\n",
    "valid_df.drop('set',axis=1).to_csv(CONFIG.DATA_FOLDER_PROCESSED+\"valid/model_data.csv\")\n",
    "\n",
    "test_df = df[df['set'] == 'test']\n",
    "test_df.drop('set',axis=1).to_csv(CONFIG.DATA_FOLDER_PROCESSED+\"test/model_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_model_data(filename = \"train\",model_data=\"model_data\",use_categories=False)\n",
    "X_valid, y_valid = get_model_data(filename = \"valid\",model_data=\"model_data\",use_categories=False)\n",
    "X_test, y_test = get_model_data(filename = \"test\",model_data=\"model_data\",use_categories=False)\n",
    "\n",
    "cat = [X_train.columns.get_loc(i) for i in [\"Team\",\"Div\",\"Opponent\"] if i in X_train.columns] \n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Initialize scaler object\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit scaler on training data\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Scale training and test data\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "lazy_clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = lazy_clf.fit(X_train, X_valid, y_train, y_valid)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lazy_report(X_test,y_test,lazy_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.005,\n",
    "    'reg_lambda': 0.01,\n",
    "    'scale_pos_weight': 1,\n",
    "    'n_estimators': 100,\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'logloss',\n",
    "    #'enable_categorical':True\n",
    "        # You can change the evaluation metric as needed\n",
    "}\n",
    "\n",
    "# Create an XGBClassifier model\n",
    "clf = XGBClassifier(**params)  # Use **params to pass the dictionary as keyword arguments\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV (if you're using GridSearchCV)\n",
    "\n",
    "# Call the custom_classification_report function\n",
    "custom_classification_report(X=X_train, y=y_train, model=clf)\n",
    "custom_classification_report(X=X_valid, y=y_valid, model=clf)\n",
    "custom_classification_report(X=X_test, y=y_test, model=clf)\n",
    "\n",
    "# Save the XGBoost model to a pickle file\n",
    "with open(CONFIG.DATA_FOLDER_MODELS + 'xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "fi = pd.DataFrame() \n",
    "fi['features'] = features\n",
    "fi['importance'] = clf.feature_importances_\n",
    "fi['importance'] = fi['importance']/sum(fi['importance'])\n",
    "fi.sort_values(by='importance',ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "params = {'learning_rate': 0.01007397282357752, 'num_leaves': 12, 'max_depth': 3, 'min_child_samples': 6}\n",
    "\n",
    "# Create a LGBMClassifier model\n",
    "clf = LGBMClassifier(**params)  # Use **params to pass the dictionary as keyword arguments\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "clf.fit(X_train, y_train,eval_metric='recall')\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "\n",
    "# Call the custom_classification_report function\n",
    "custom_classification_report(X=X_train, y=y_train, model=clf)\n",
    "custom_classification_report(X=X_valid, y=y_valid, model=clf)\n",
    "custom_classification_report(X=X_test, y=y_test, model=clf)\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(CONFIG.DATA_FOLDER_MODELS + 'lgb.pkl', 'wb'))\n",
    "\n",
    "fi = pd.DataFrame() \n",
    "fi['features'] = features\n",
    "fi['importance'] = clf.booster_.feature_importance(importance_type='gain')  \n",
    "fi['importance'] = fi['importance']/sum(fi['importance'])\n",
    "fi.sort_values(by='importance',ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch für bestes Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "params = {'learning_rate': 0.01007397282357752, 'num_leaves': 12, 'max_depth': 3, 'min_child_samples': 6}\n",
    "# Create a LGBMClassifier model\n",
    "clf = LGBMClassifier(params)\n",
    "\n",
    "# Create a GridSearchCV object to perform grid search\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "custom_classification_report(X = X_test,y = y_test,model = grid_search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "    }\n",
    "\n",
    "    # Split your data into training and validation sets\n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    # Specify the number of boosting rounds\n",
    "    num_boost_round = 10000\n",
    "\n",
    "    # Initialize variables for early stopping\n",
    "    early_stopping_rounds = 100\n",
    "    early_stopping_counter = 0\n",
    "    best_logloss = float('inf')\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    clf = lgb.LGBMClassifier(**params, n_estimators=num_boost_round)\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    val_pred = clf.predict_proba(X_valid, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    logloss = log_loss(y_valid, val_pred)\n",
    "\n",
    "    if logloss < best_logloss:\n",
    "        best_logloss = logloss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_rounds:\n",
    "            return best_logloss  # Early stopping\n",
    "\n",
    "    return best_logloss\n",
    "\n",
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a LightGBM classifier with the best hyperparameters\n",
    "clf = lgb.LGBMClassifier(**best_params, n_estimators=100)  # You can specify a large number of estimators\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=100)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = clf.predict(X_valid)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "# Define pretrainer model architecture\n",
    "pretrainer = TabNetPretrainer(\n",
    "optimizer_fn=torch.optim.Adam,\n",
    "optimizer_params=dict(lr=2e-2),\n",
    "mask_type=\"entmax\"\n",
    ")\n",
    "\n",
    "# Train pretrainer model on training data\n",
    "pretrainer.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_valid],\n",
    "    max_epochs=1000,\n",
    "    patience=30,\n",
    "    pretraining_ratio=0.8,\n",
    "    batch_size= 64\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# Define hyperparameters\n",
    "n_d = 8\n",
    "n_a = 8\n",
    "n_steps = 3\n",
    "gamma = 1\n",
    "lambda_sparse = 0.001\n",
    "lr = 0.0001\n",
    "batch_size = 16\n",
    "max_epochs = 150\n",
    "\n",
    "# Create TabNet classifier\n",
    "clf = TabNetClassifier(n_d=n_d, n_a=n_a, cat_dims=cat,n_steps=n_steps, gamma=gamma, lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=lr), mask_type='entmax', device_name='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Train TabNet classifier\n",
    "clf.fit(X_train=X_train, y_train=y_train,     eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'], eval_metric=['auc','balanced_accuracy'],batch_size=batch_size, max_epochs=max_epochs, patience=0)\n",
    "# from_unsupervised=pickle.load(open('tabnet.pkl', 'rb'))\n",
    "\n",
    "import pickle\n",
    "pickle.dump(clf, open('tabnet.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('tabnet.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(open('tabnet.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(clf.history['loss'], label='Validation Loss')\n",
    "plt.plot(clf.history['valid_auc'], label='AUC')\n",
    "plt.plot(clf.history['valid_balanced_accuracy'], label='Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "r = classification_report(y_pred=y_pred,y_true=y_test)\n",
    "print(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erklärbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = pd.Series(clf.feature_importances_)\n",
    "f_i.index = features\n",
    "f_i.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"BW_opponent_odd_pred\",\"B365_Opponent\",\"Avg_Opponent\",\"IW_Team\",\"Span_Draw\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(f_i>0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss\n",
    "\n",
    "def load_dataset():\n",
    "    # Load your dataset here\n",
    "    # Replace this with your dataset loading code\n",
    "    # X and y should be your feature and target variables\n",
    "    pass\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    shrink_threshold = trial.suggest_float(\"shrink_threshold\", 0.0, 1.0)\n",
    "    \n",
    "    X_train, y_train = get_model_data(filename = \"Train\")\n",
    "    X_valid, y_valid = get_model_data(filename = \"Valid\")\n",
    "    X_test, y_test = get_model_data(filename = \"Test\")\n",
    "    \n",
    "    # Create and train the NearestCentroid classifier with the suggested parameters\n",
    "    clf = NearestCentroid(shrink_threshold=shrink_threshold)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    \n",
    "    # Calculate the accuracy of the model\n",
    "    score = brier_score_loss(y_valid, y_pred)\n",
    "    \n",
    "    return brier_score_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset\n",
    "    \n",
    "    # Specify the SQLite database file for the study\n",
    "    study_name = \"neareast_centroid_optimization.db\"\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=study_name)\n",
    "\n",
    "    # Optimize the study\n",
    "    study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "    # Get the best parameters and their corresponding accuracy\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "\n",
    "    # # Save the study to the specified SQLite database file\n",
    "    # study.trials_dataframe().to_sql(study_name, \"sqlite:///{}\".format(study_name), if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf = NearestCentroid(shrink_threshold=0.95)\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
