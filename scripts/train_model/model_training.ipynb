{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "os.chdir(\"c:/Users/Robert/Documents/Projekte/dev/sport_betting/\")\n",
    "import config as CONFIG\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.data.provide_data import get_model_data\n",
    "from src.models.evaluate import custom_classification_report, custom_lazy_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/model_data_deployment.csv\",index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set'] = \"train\"\n",
    "df.loc[df.year > 2020, 'set'] = \"valid\"\n",
    "df.loc[df.year > 2022, 'set'] = \"test\"\n",
    "\n",
    "# df = df.drop([\"B365_Opponent\",\"B365_Draw\",\"B365_Team\",'B365_Team_odd_pred', 'B365_opponent_odd_pred', 'B365_Team_draw_pred'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['set'] == 'train']\n",
    "train_df.drop('set',axis=1).to_csv(CONFIG.DATA_FOLDER_PROCESSED+\"train/model_data.csv\")\n",
    "\n",
    "valid_df = df[df['set'] == 'valid']\n",
    "valid_df.drop('set',axis=1).to_csv(CONFIG.DATA_FOLDER_PROCESSED+\"valid/model_data.csv\")\n",
    "\n",
    "test_df = df[df['set'] == 'test']\n",
    "test_df.drop('set',axis=1).to_csv(CONFIG.DATA_FOLDER_PROCESSED+\"test/model_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_model_data(filename = \"train\",model_data=\"model_data\",use_categories=False)\n",
    "X_valid, y_valid = get_model_data(filename = \"valid\",model_data=\"model_data\",use_categories=False)\n",
    "X_test, y_test = get_model_data(filename = \"test\",model_data=\"model_data\",use_categories=False)\n",
    "\n",
    "cat = [X_train.columns.get_loc(i) for i in [\"Team\",\"Div\",\"Opponent\"] if i in X_train.columns] \n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Initialize scaler object\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit scaler on training data\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Scale training and test data\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "lazy_clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = lazy_clf.fit(X_train, X_valid, y_train, y_valid)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lazy_report(X_test,y_test,lazy_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.90      0.79     69984\n",
      "        True       0.67      0.35      0.46     40428\n",
      "\n",
      "    accuracy                           0.70    110412\n",
      "   macro avg       0.69      0.62      0.62    110412\n",
      "weighted avg       0.69      0.70      0.67    110412\n",
      "\n",
      "AUC 0.733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.90      0.78     16936\n",
      "        True       0.64      0.32      0.43      9886\n",
      "\n",
      "    accuracy                           0.68     26822\n",
      "   macro avg       0.67      0.61      0.60     26822\n",
      "weighted avg       0.68      0.68      0.65     26822\n",
      "\n",
      "AUC 0.703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.89      0.78      3929\n",
      "        True       0.64      0.34      0.44      2347\n",
      "\n",
      "    accuracy                           0.68      6276\n",
      "   macro avg       0.67      0.61      0.61      6276\n",
      "weighted avg       0.67      0.68      0.65      6276\n",
      "\n",
      "AUC 0.721\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Avg_Team</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WH_Team_odd_pred</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Max_Team</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WH_Team</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Min_Team</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Avg_Opponent</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IW_Opponent</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>IW_Team_odd_pred</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IW_Team</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Max_Opponent</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            features  importance\n",
       "11          Avg_Team        0.30\n",
       "27  WH_Team_odd_pred        0.14\n",
       "9           Max_Team        0.11\n",
       "3            WH_Team        0.10\n",
       "10          Min_Team        0.06\n",
       "16      Avg_Opponent        0.04\n",
       "4        IW_Opponent        0.02\n",
       "24  IW_Team_odd_pred        0.02\n",
       "6            IW_Team        0.02\n",
       "14      Max_Opponent        0.01"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 10,\n",
    "    'min_child_weight': 10,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.005,\n",
    "    'reg_lambda': 0.01,\n",
    "    'scale_pos_weight': 1,\n",
    "    'n_estimators': 100,\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'aucpr',\n",
    "    #'enable_categorical':True\n",
    "        # You can change the evaluation metric as needed\n",
    "}\n",
    "\n",
    "# Create an XGBClassifier model\n",
    "clf = XGBClassifier(**params)  # Use **params to pass the dictionary as keyword arguments\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV (if you're using GridSearchCV)\n",
    "\n",
    "# Call the custom_classification_report function\n",
    "custom_classification_report(X=X_train, y=y_train, model=clf)\n",
    "custom_classification_report(X=X_valid, y=y_valid, model=clf)\n",
    "custom_classification_report(X=X_test, y=y_test, model=clf)\n",
    "\n",
    "# Save the XGBoost model to a pickle file\n",
    "with open(CONFIG.DATA_FOLDER_MODELS + 'xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "fi = pd.DataFrame() \n",
    "fi['features'] = features\n",
    "fi['importance'] = clf.feature_importances_\n",
    "fi['importance'] = fi['importance']/sum(fi['importance'])\n",
    "fi.sort_values(by='importance',ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pd.Series(clf.predict_proba(X_test)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_test.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "params = {'learning_rate': 0.01007397282357752, 'num_leaves': 12, 'max_depth': 3, 'min_child_samples': 6}\n",
    "\n",
    "# Create a LGBMClassifier model\n",
    "clf = LGBMClassifier(**params)  # Use **params to pass the dictionary as keyword arguments\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "clf.fit(X_train, y_train,eval_metric='recall')\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "\n",
    "# Call the custom_classification_report function\n",
    "custom_classification_report(X=X_train, y=y_train, model=clf)\n",
    "custom_classification_report(X=X_valid, y=y_valid, model=clf)\n",
    "custom_classification_report(X=X_test, y=y_test, model=clf)\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(CONFIG.DATA_FOLDER_MODELS + 'lgb.pkl', 'wb'))\n",
    "\n",
    "fi = pd.DataFrame() \n",
    "fi['features'] = features\n",
    "fi['importance'] = clf.booster_.feature_importance(importance_type='gain')  \n",
    "fi['importance'] = fi['importance']/sum(fi['importance'])\n",
    "fi.sort_values(by='importance',ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch für bestes Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "params = {'learning_rate': 0.01007397282357752, 'num_leaves': 12, 'max_depth': 3, 'min_child_samples': 6}\n",
    "# Create a LGBMClassifier model\n",
    "clf = LGBMClassifier(params)\n",
    "\n",
    "# Create a GridSearchCV object to perform grid search\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "custom_classification_report(X = X_test,y = y_test,model = grid_search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "    }\n",
    "\n",
    "    # Split your data into training and validation sets\n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    # Specify the number of boosting rounds\n",
    "    num_boost_round = 10000\n",
    "\n",
    "    # Initialize variables for early stopping\n",
    "    early_stopping_rounds = 100\n",
    "    early_stopping_counter = 0\n",
    "    best_logloss = float('inf')\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    clf = lgb.LGBMClassifier(**params, n_estimators=num_boost_round)\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    val_pred = clf.predict_proba(X_valid, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    logloss = log_loss(y_valid, val_pred)\n",
    "\n",
    "    if logloss < best_logloss:\n",
    "        best_logloss = logloss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_rounds:\n",
    "            return best_logloss  # Early stopping\n",
    "\n",
    "    return best_logloss\n",
    "\n",
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a LightGBM classifier with the best hyperparameters\n",
    "clf = lgb.LGBMClassifier(**best_params, n_estimators=100)  # You can specify a large number of estimators\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=100)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = clf.predict(X_valid)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "# Define pretrainer model architecture\n",
    "pretrainer = TabNetPretrainer(\n",
    "optimizer_fn=torch.optim.Adam,\n",
    "optimizer_params=dict(lr=2e-2),\n",
    "mask_type=\"entmax\"\n",
    ")\n",
    "\n",
    "# Train pretrainer model on training data\n",
    "pretrainer.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_valid],\n",
    "    max_epochs=1000,\n",
    "    patience=30,\n",
    "    pretraining_ratio=0.8,\n",
    "    batch_size= 64\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# Define hyperparameters\n",
    "n_d = 8\n",
    "n_a = 8\n",
    "n_steps = 3\n",
    "gamma = 1\n",
    "lambda_sparse = 0.001\n",
    "lr = 0.0001\n",
    "batch_size = 16\n",
    "max_epochs = 150\n",
    "\n",
    "# Create TabNet classifier\n",
    "clf = TabNetClassifier(n_d=n_d, n_a=n_a, cat_dims=cat,n_steps=n_steps, gamma=gamma, lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=lr), mask_type='entmax', device_name='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Train TabNet classifier\n",
    "clf.fit(X_train=X_train, y_train=y_train,     eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'], eval_metric=['auc','balanced_accuracy'],batch_size=batch_size, max_epochs=max_epochs, patience=0)\n",
    "# from_unsupervised=pickle.load(open('tabnet.pkl', 'rb'))\n",
    "\n",
    "import pickle\n",
    "pickle.dump(clf, open('tabnet.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('tabnet.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(open('tabnet.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(clf.history['loss'], label='Validation Loss')\n",
    "plt.plot(clf.history['valid_auc'], label='AUC')\n",
    "plt.plot(clf.history['valid_balanced_accuracy'], label='Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "r = classification_report(y_pred=y_pred,y_true=y_test)\n",
    "print(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erklärbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = pd.Series(clf.feature_importances_)\n",
    "f_i.index = features\n",
    "f_i.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"BW_opponent_odd_pred\",\"B365_Opponent\",\"Avg_Opponent\",\"IW_Team\",\"Span_Draw\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(f_i>0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss\n",
    "\n",
    "def load_dataset():\n",
    "    # Load your dataset here\n",
    "    # Replace this with your dataset loading code\n",
    "    # X and y should be your feature and target variables\n",
    "    pass\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    shrink_threshold = trial.suggest_float(\"shrink_threshold\", 0.0, 1.0)\n",
    "    \n",
    "    X_train, y_train = get_model_data(filename = \"Train\")\n",
    "    X_valid, y_valid = get_model_data(filename = \"Valid\")\n",
    "    X_test, y_test = get_model_data(filename = \"Test\")\n",
    "    \n",
    "    # Create and train the NearestCentroid classifier with the suggested parameters\n",
    "    clf = NearestCentroid(shrink_threshold=shrink_threshold)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    \n",
    "    # Calculate the accuracy of the model\n",
    "    score = brier_score_loss(y_valid, y_pred)\n",
    "    \n",
    "    return brier_score_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset\n",
    "    \n",
    "    # Specify the SQLite database file for the study\n",
    "    study_name = \"neareast_centroid_optimization.db\"\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=study_name)\n",
    "\n",
    "    # Optimize the study\n",
    "    study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "    # Get the best parameters and their corresponding accuracy\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "\n",
    "    # # Save the study to the specified SQLite database file\n",
    "    # study.trials_dataframe().to_sql(study_name, \"sqlite:///{}\".format(study_name), if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf = NearestCentroid(shrink_threshold=0.95)\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
