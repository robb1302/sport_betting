{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "os.chdir(\"c:/Users/Robert/Documents/Projekte/dev/sport_betting/\")\n",
    "import config as CONFIG\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.provide_data import get_model_data\n",
    "from src.models.evaluate import custom_classification_report, custom_lazy_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 5246\n",
      "Valid 1952\n",
      "Test 1952\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_model_data(filename = \"Train\")\n",
    "X_valid, y_valid = get_model_data(filename = \"Valid\")\n",
    "X_test, y_test = get_model_data(filename = \"Test\")\n",
    "\n",
    "cat = [X_train.columns.get_loc(i) for i in [\"Team\",\"Div\",\"Opponent\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale training and test data\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robert\\Documents\\Projekte\\dev\\sport_betting\\.venv\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "clf = pickle.load(open(CONFIG.DATA_FOLDER_MODELS+'lgb.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.loads(clf, open(CONFIG.DATA_FOLDER_MODELS + 'lgb.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1773067971.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    from scripts.02_process_data.preprocess_team_opponent import preprocess_data\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "from scripts.02_process_data.preprocess_team_opponent import preprocess_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch f√ºr bestes Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B365_Team</td>\n",
       "      <td>0.468098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>B365_Team_odd_pred</td>\n",
       "      <td>0.142169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BW_Team_odd_pred</td>\n",
       "      <td>0.077514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Avg_Opponent</td>\n",
       "      <td>0.047664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Avg_Team</td>\n",
       "      <td>0.039862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BW_Draw</td>\n",
       "      <td>0.036606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BW_Opponent</td>\n",
       "      <td>0.031168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Min_Draw</td>\n",
       "      <td>0.028843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Max_Team</td>\n",
       "      <td>0.025619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B365_Opponent</td>\n",
       "      <td>0.025413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              features  importance\n",
       "7            B365_Team    0.468098\n",
       "30  B365_Team_odd_pred    0.142169\n",
       "36    BW_Team_odd_pred    0.077514\n",
       "22        Avg_Opponent    0.047664\n",
       "17            Avg_Team    0.039862\n",
       "3              BW_Draw    0.036606\n",
       "2          BW_Opponent    0.031168\n",
       "26            Min_Draw    0.028843\n",
       "15            Max_Team    0.025619\n",
       "5        B365_Opponent    0.025413"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.DataFrame() \n",
    "fi['features'] = features\n",
    "fi['importance'] = clf.booster_.feature_importance(importance_type='gain')  \n",
    "fi['importance'] = fi['importance']/sum(fi['importance'])\n",
    "fi.sort_values(by='importance',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>B365_Team_odd_pred</td>\n",
       "      <td>0.138571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B365_Team</td>\n",
       "      <td>0.127143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BW_Opponent</td>\n",
       "      <td>0.078571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BW_Draw</td>\n",
       "      <td>0.058571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Max_Team</td>\n",
       "      <td>0.055714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IW_Opponent</td>\n",
       "      <td>0.052857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Avg_Opponent</td>\n",
       "      <td>0.048571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ratio_Draw</td>\n",
       "      <td>0.047143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Span_Draw_last_4_games</td>\n",
       "      <td>0.047143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>B365_Team_last_4_games</td>\n",
       "      <td>0.044286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features  importance\n",
       "30      B365_Team_odd_pred    0.138571\n",
       "7                B365_Team    0.127143\n",
       "2              BW_Opponent    0.078571\n",
       "3                  BW_Draw    0.058571\n",
       "15                Max_Team    0.055714\n",
       "8              IW_Opponent    0.052857\n",
       "22            Avg_Opponent    0.048571\n",
       "29              Ratio_Draw    0.047143\n",
       "44  Span_Draw_last_4_games    0.047143\n",
       "39  B365_Team_last_4_games    0.044286"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(open('tabnet.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(clf.history['loss'], label='Validation Loss')\n",
    "plt.plot(clf.history['valid_auc'], label='AUC')\n",
    "plt.plot(clf.history['valid_balanced_accuracy'], label='Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "r = classification_report(y_pred=y_pred,y_true=y_test)\n",
    "print(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erkl√§rbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = pd.Series(clf.feature_importances_)\n",
    "f_i.index = features\n",
    "f_i.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"BW_opponent_odd_pred\",\"B365_Opponent\",\"Avg_Opponent\",\"IW_Team\",\"Span_Draw\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(f_i>0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss\n",
    "\n",
    "def load_dataset():\n",
    "    # Load your dataset here\n",
    "    # Replace this with your dataset loading code\n",
    "    # X and y should be your feature and target variables\n",
    "    pass\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    shrink_threshold = trial.suggest_float(\"shrink_threshold\", 0.0, 1.0)\n",
    "    \n",
    "    X_train, y_train = get_model_data(filename = \"Train\")\n",
    "    X_valid, y_valid = get_model_data(filename = \"Valid\")\n",
    "    X_test, y_test = get_model_data(filename = \"Test\")\n",
    "    \n",
    "    # Create and train the NearestCentroid classifier with the suggested parameters\n",
    "    clf = NearestCentroid(shrink_threshold=shrink_threshold)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    \n",
    "    # Calculate the accuracy of the model\n",
    "    score = brier_score_loss(y_valid, y_pred)\n",
    "    \n",
    "    return brier_score_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset\n",
    "    \n",
    "    # Specify the SQLite database file for the study\n",
    "    study_name = \"neareast_centroid_optimization.db\"\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=study_name)\n",
    "\n",
    "    # Optimize the study\n",
    "    study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "    # Get the best parameters and their corresponding accuracy\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "\n",
    "    # # Save the study to the specified SQLite database file\n",
    "    # study.trials_dataframe().to_sql(study_name, \"sqlite:///{}\".format(study_name), if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf = NearestCentroid(shrink_threshold=0.95)\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
