{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "os.chdir(\"c:/Users/Robert/Documents/Projekte/dev/sport_betting/\")\n",
    "import config as CONFIG\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.data.provide_data import get_model_data\n",
    "from src.models.evaluate import custom_classification_report, custom_lazy_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.process_data.preprocess_team_opponent_deployment import preprocess_data,load_team_opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = load_team_opponent(filename_main=\"data/fixtures/update.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.WH_Team.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Div                0\n",
       "Date               0\n",
       "Team               0\n",
       "Opponent           0\n",
       "FTG_Team         332\n",
       "FTG_Opponent     332\n",
       "R                332\n",
       "B365_Team          0\n",
       "B365_Draw          0\n",
       "B365_Opponent      0\n",
       "BW_Team          254\n",
       "BW_Draw          254\n",
       "BW_Opponent      254\n",
       "IW_Team            0\n",
       "IW_Draw            0\n",
       "IW_Opponent        0\n",
       "WH_Team            0\n",
       "WH_Draw            0\n",
       "WH_Opponent        0\n",
       "VC_Team            6\n",
       "VC_Draw            6\n",
       "VC_Opponent        6\n",
       "Max_Team           0\n",
       "Max_Draw           0\n",
       "Max_Opponent       0\n",
       "Avg_Team           0\n",
       "Avg_Draw           0\n",
       "Avg_Opponent       0\n",
       "atHome             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start preprocessing\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atHome</th>\n",
       "      <th>Div</th>\n",
       "      <th>Target</th>\n",
       "      <th>BW_Team</th>\n",
       "      <th>BW_Draw</th>\n",
       "      <th>BW_Opponent</th>\n",
       "      <th>IW_Team</th>\n",
       "      <th>IW_Draw</th>\n",
       "      <th>IW_Opponent</th>\n",
       "      <th>Team</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Max_Team</th>\n",
       "      <th>Min_Team</th>\n",
       "      <th>Avg_Team</th>\n",
       "      <th>Span_Team</th>\n",
       "      <th>Ratio_Team</th>\n",
       "      <th>Max_Opponent</th>\n",
       "      <th>Min_Opponent</th>\n",
       "      <th>Avg_Opponent</th>\n",
       "      <th>Span_Opponent</th>\n",
       "      <th>Ratio_Opponent</th>\n",
       "      <th>Max_Draw</th>\n",
       "      <th>Min_Draw</th>\n",
       "      <th>Avg_Draw</th>\n",
       "      <th>Span_Draw</th>\n",
       "      <th>Ratio_Draw</th>\n",
       "      <th>IW_Team_odd_pred</th>\n",
       "      <th>IW_opponent_odd_pred</th>\n",
       "      <th>IW_Team_draw_pred</th>\n",
       "      <th>BW_Team_odd_pred</th>\n",
       "      <th>BW_opponent_odd_pred</th>\n",
       "      <th>BW_Team_draw_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>F2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.05</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>St Etienne</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.385057</td>\n",
       "      <td>0.235632</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>I1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.60</td>\n",
       "      <td>Salernitana</td>\n",
       "      <td>Udinese</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>I1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1.45</td>\n",
       "      <td>Cagliari</td>\n",
       "      <td>Inter</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527344</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>P1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.45</td>\n",
       "      <td>Rio Ave</td>\n",
       "      <td>Porto</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>0.347490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>SP1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.80</td>\n",
       "      <td>Getafe</td>\n",
       "      <td>Alaves</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atHome  Div  Target  BW_Team  BW_Draw  BW_Opponent  IW_Team  IW_Draw  \\\n",
       "0    True   F2   False      NaN      NaN          NaN     3.35     3.30   \n",
       "1    True   I1   False      NaN      NaN          NaN     2.70     3.30   \n",
       "2    True   I1   False      NaN      NaN          NaN     6.75     4.60   \n",
       "3    True   P1   False      NaN      NaN          NaN     7.00     4.50   \n",
       "4    True  SP1   False      NaN      NaN          NaN     2.25     2.95   \n",
       "\n",
       "   IW_Opponent         Team    Opponent  month  year  Max_Team  Min_Team  \\\n",
       "0         2.05       Annecy  St Etienne      8  2023       NaN       NaN   \n",
       "1         2.60  Salernitana     Udinese      8  2023       NaN       NaN   \n",
       "2         1.45     Cagliari       Inter      8  2023       NaN       NaN   \n",
       "3         1.45      Rio Ave       Porto      8  2023       NaN       NaN   \n",
       "4         3.80       Getafe      Alaves      8  2023       NaN       NaN   \n",
       "\n",
       "   Avg_Team  Span_Team  Ratio_Team  Max_Opponent  Min_Opponent  Avg_Opponent  \\\n",
       "0       NaN        NaN         NaN           NaN           NaN           NaN   \n",
       "1       NaN        NaN         NaN           NaN           NaN           NaN   \n",
       "2       NaN        NaN         NaN           NaN           NaN           NaN   \n",
       "3       NaN        NaN         NaN           NaN           NaN           NaN   \n",
       "4       NaN        NaN         NaN           NaN           NaN           NaN   \n",
       "\n",
       "   Span_Opponent  Ratio_Opponent  Max_Draw  Min_Draw  Avg_Draw  Span_Draw  \\\n",
       "0            NaN             NaN       NaN       NaN       NaN        NaN   \n",
       "1            NaN             NaN       NaN       NaN       NaN        NaN   \n",
       "2            NaN             NaN       NaN       NaN       NaN        NaN   \n",
       "3            NaN             NaN       NaN       NaN       NaN        NaN   \n",
       "4            NaN             NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "   Ratio_Draw  IW_Team_odd_pred  IW_opponent_odd_pred  IW_Team_draw_pred  \\\n",
       "0         NaN          0.385057              0.235632           0.379310   \n",
       "1         NaN          0.313953              0.302326           0.383721   \n",
       "2         NaN          0.527344              0.113281           0.359375   \n",
       "3         NaN          0.540541              0.111969           0.347490   \n",
       "4         NaN          0.250000              0.422222           0.327778   \n",
       "\n",
       "   BW_Team_odd_pred  BW_opponent_odd_pred  BW_Team_draw_pred  \n",
       "0               NaN                   NaN                NaN  \n",
       "1               NaN                   NaN                NaN  \n",
       "2               NaN                   NaN                NaN  \n",
       "3               NaN                   NaN                NaN  \n",
       "4               NaN                   NaN                NaN  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "clf = pickle.load(open(CONFIG.DATA_FOLDER_MODELS+\"xgb.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 110524\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_model_data(filename = \"train\",model_data=\"model_data\",use_categories=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on training data\n",
    "scaler.fit(X_train)\n",
    "df_scaled = scaler.transform(df[X_train.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atHome</th>\n",
       "      <th>BW_Opponent</th>\n",
       "      <th>BW_Draw</th>\n",
       "      <th>BW_Team</th>\n",
       "      <th>IW_Opponent</th>\n",
       "      <th>IW_Draw</th>\n",
       "      <th>IW_Team</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Max_Team</th>\n",
       "      <th>Min_Team</th>\n",
       "      <th>Avg_Team</th>\n",
       "      <th>Span_Team</th>\n",
       "      <th>Ratio_Team</th>\n",
       "      <th>Max_Opponent</th>\n",
       "      <th>Min_Opponent</th>\n",
       "      <th>Avg_Opponent</th>\n",
       "      <th>Span_Opponent</th>\n",
       "      <th>Ratio_Opponent</th>\n",
       "      <th>Max_Draw</th>\n",
       "      <th>Min_Draw</th>\n",
       "      <th>Avg_Draw</th>\n",
       "      <th>Span_Draw</th>\n",
       "      <th>Ratio_Draw</th>\n",
       "      <th>IW_Team_odd_pred</th>\n",
       "      <th>IW_opponent_odd_pred</th>\n",
       "      <th>IW_Team_draw_pred</th>\n",
       "      <th>BW_Team_odd_pred</th>\n",
       "      <th>BW_opponent_odd_pred</th>\n",
       "      <th>BW_Team_draw_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.35</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.385057</td>\n",
       "      <td>0.235632</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.70</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.60</td>\n",
       "      <td>6.75</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527344</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>0.347490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.25</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.433333</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.020833</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.358382</td>\n",
       "      <td>0.283237</td>\n",
       "      <td>0.358382</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>0.264368</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220430</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.327957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.70</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.73</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167473</td>\n",
       "      <td>0.454985</td>\n",
       "      <td>0.377541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422111</td>\n",
       "      <td>0.175879</td>\n",
       "      <td>0.402010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     atHome  BW_Opponent  BW_Draw  BW_Team  IW_Opponent  IW_Draw  IW_Team  \\\n",
       "0      True          NaN      NaN      NaN         2.05     3.30     3.35   \n",
       "1      True          NaN      NaN      NaN         2.60     3.30     2.70   \n",
       "2      True          NaN      NaN      NaN         1.45     4.60     6.75   \n",
       "3      True          NaN      NaN      NaN         1.45     4.50     7.00   \n",
       "4      True          NaN      NaN      NaN         3.80     2.95     2.25   \n",
       "..      ...          ...      ...      ...          ...      ...      ...   \n",
       "327   False          2.4      3.0      3.0         2.45     3.10     3.10   \n",
       "328   False          NaN      NaN      NaN         2.30     3.20     3.20   \n",
       "329   False          NaN      NaN      NaN         4.20     3.05     2.05   \n",
       "330   False          NaN      NaN      NaN         4.70     3.90     1.73   \n",
       "331   False          NaN      NaN      NaN         1.75     4.00     4.20   \n",
       "\n",
       "     month  year  Max_Team  Min_Team  Avg_Team  Span_Team  Ratio_Team  \\\n",
       "0        8  2023       NaN       NaN       NaN        NaN         NaN   \n",
       "1        8  2023       NaN       NaN       NaN        NaN         NaN   \n",
       "2        8  2023       NaN       NaN       NaN        NaN         NaN   \n",
       "3        8  2023       NaN       NaN       NaN        NaN         NaN   \n",
       "4        8  2023       NaN       NaN       NaN        NaN         NaN   \n",
       "..     ...   ...       ...       ...       ...        ...         ...   \n",
       "327      8  2023       3.1       3.0  3.066667        0.1    1.033333   \n",
       "328      8  2023       NaN       NaN       NaN        NaN         NaN   \n",
       "329      8  2023       NaN       NaN       NaN        NaN         NaN   \n",
       "330      8  2023       NaN       NaN       NaN        NaN         NaN   \n",
       "331      8  2023       NaN       NaN       NaN        NaN         NaN   \n",
       "\n",
       "     Max_Opponent  Min_Opponent  Avg_Opponent  Span_Opponent  Ratio_Opponent  \\\n",
       "0             NaN           NaN           NaN            NaN             NaN   \n",
       "1             NaN           NaN           NaN            NaN             NaN   \n",
       "2             NaN           NaN           NaN            NaN             NaN   \n",
       "3             NaN           NaN           NaN            NaN             NaN   \n",
       "4             NaN           NaN           NaN            NaN             NaN   \n",
       "..            ...           ...           ...            ...             ...   \n",
       "327          2.45           2.4      2.433333           0.05        1.020833   \n",
       "328           NaN           NaN           NaN            NaN             NaN   \n",
       "329           NaN           NaN           NaN            NaN             NaN   \n",
       "330           NaN           NaN           NaN            NaN             NaN   \n",
       "331           NaN           NaN           NaN            NaN             NaN   \n",
       "\n",
       "     Max_Draw  Min_Draw  Avg_Draw  Span_Draw  Ratio_Draw  IW_Team_odd_pred  \\\n",
       "0         NaN       NaN       NaN        NaN         NaN          0.385057   \n",
       "1         NaN       NaN       NaN        NaN         NaN          0.313953   \n",
       "2         NaN       NaN       NaN        NaN         NaN          0.527344   \n",
       "3         NaN       NaN       NaN        NaN         NaN          0.540541   \n",
       "4         NaN       NaN       NaN        NaN         NaN          0.250000   \n",
       "..        ...       ...       ...        ...         ...               ...   \n",
       "327       3.1       3.0  3.066667        0.1    1.033333          0.358382   \n",
       "328       NaN       NaN       NaN        NaN         NaN          0.367816   \n",
       "329       NaN       NaN       NaN        NaN         NaN          0.220430   \n",
       "330       NaN       NaN       NaN        NaN         NaN          0.167473   \n",
       "331       NaN       NaN       NaN        NaN         NaN          0.422111   \n",
       "\n",
       "     IW_opponent_odd_pred  IW_Team_draw_pred  BW_Team_odd_pred  \\\n",
       "0                0.235632           0.379310               NaN   \n",
       "1                0.302326           0.383721               NaN   \n",
       "2                0.113281           0.359375               NaN   \n",
       "3                0.111969           0.347490               NaN   \n",
       "4                0.422222           0.327778               NaN   \n",
       "..                    ...                ...               ...   \n",
       "327              0.283237           0.358382          0.357143   \n",
       "328              0.264368           0.367816               NaN   \n",
       "329              0.451613           0.327957               NaN   \n",
       "330              0.454985           0.377541               NaN   \n",
       "331              0.175879           0.402010               NaN   \n",
       "\n",
       "     BW_opponent_odd_pred  BW_Team_draw_pred  \n",
       "0                     NaN                NaN  \n",
       "1                     NaN                NaN  \n",
       "2                     NaN                NaN  \n",
       "3                     NaN                NaN  \n",
       "4                     NaN                NaN  \n",
       "..                    ...                ...  \n",
       "327              0.285714           0.357143  \n",
       "328                   NaN                NaN  \n",
       "329                   NaN                NaN  \n",
       "330                   NaN                NaN  \n",
       "331                   NaN                NaN  \n",
       "\n",
       "[332 rows x 30 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(clf.predict_proba(df_scaled)[:,1],columns=[\"preds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[[\"Team\",\"Opponent\",\"atHome\",\"Div\"]] = df[[\"Team\",\"Opponent\",\"atHome\",\"Div\"]].values\n",
    "preds['atHome'] = preds['atHome'].astype('bool')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to identify home and away teams\n",
    "home_mask = preds['atHome']\n",
    "away_mask = ~home_mask\n",
    "\n",
    "# Create separate DataFrames for home and away teams\n",
    "home_df = preds[home_mask].rename(columns={'Team': 'Home', 'Opponent': 'Away', 'preds': 'preds_home'})\n",
    "away_df = preds[away_mask].rename(columns={'Team': 'Away', 'Opponent': 'Home', 'preds': 'preds_away'})\n",
    "\n",
    "# Merge the two DataFrames based on the 'Home' and 'Away' columns\n",
    "result_df = pd.merge(home_df[[\"Div\",'Home', 'Away', 'preds_home']], away_df[['Home', 'Away', 'preds_away']], on=['Home', 'Away'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"preds_draw\"] = 1- (result_df[\"preds_home\"] + result_df[\"preds_away\"])\n",
    "result_df.Div.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df.Div == \"D1\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "lazy_clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = lazy_clf.fit(X_train, X_valid, y_train, y_valid)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lazy_report(X_test,y_test,lazy_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "params = {\n",
    "    'learning_rate': 0.01007397282357752,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.005,\n",
    "    'reg_lambda': 0.01,\n",
    "    'scale_pos_weight': 1,\n",
    "    'n_estimators': 100,\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'logloss'  # You can change the evaluation metric as needed\n",
    "}\n",
    "\n",
    "# Create an XGBClassifier model\n",
    "clf = XGBClassifier(**params)  # Use **params to pass the dictionary as keyword arguments\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV (if you're using GridSearchCV)\n",
    "\n",
    "# Call the custom_classification_report function\n",
    "custom_classification_report(X=X_train, y=y_train, model=clf)\n",
    "custom_classification_report(X=X_valid, y=y_valid, model=clf)\n",
    "custom_classification_report(X=X_test, y=y_test, model=clf)\n",
    "\n",
    "# Save the XGBoost model to a pickle file\n",
    "with open(CONFIG.DATA_FOLDER_MODELS + 'xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Div']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "params = {'learning_rate': 0.01007397282357752, 'num_leaves': 12, 'max_depth': 3, 'min_child_samples': 6}\n",
    "\n",
    "# Create a LGBMClassifier model\n",
    "clf = LGBMClassifier(**params)  # Use **params to pass the dictionary as keyword arguments\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "clf.fit(X_train, y_train,eval_metric='recall',categorical_feature='Div')\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "\n",
    "# Call the custom_classification_report function\n",
    "custom_classification_report(X=X_train, y=y_train, model=clf)\n",
    "custom_classification_report(X=X_valid, y=y_valid, model=clf)\n",
    "custom_classification_report(X=X_test, y=y_test, model=clf)\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(CONFIG.DATA_FOLDER_MODELS + 'lgb.pkl', 'wb'))\n",
    "\n",
    "fi = pd.DataFrame() \n",
    "fi['features'] = features\n",
    "fi['importance'] = clf.booster_.feature_importance(importance_type='gain')  \n",
    "fi['importance'] = fi['importance']/sum(fi['importance'])\n",
    "fi.sort_values(by='importance',ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch für bestes Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "params = {'learning_rate': 0.01007397282357752, 'num_leaves': 12, 'max_depth': 3, 'min_child_samples': 6}\n",
    "# Create a LGBMClassifier model\n",
    "clf = LGBMClassifier(params)\n",
    "\n",
    "# Create a GridSearchCV object to perform grid search\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "custom_classification_report(X = X_test,y = y_test,model = grid_search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "    }\n",
    "\n",
    "    # Split your data into training and validation sets\n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    # Specify the number of boosting rounds\n",
    "    num_boost_round = 10000\n",
    "\n",
    "    # Initialize variables for early stopping\n",
    "    early_stopping_rounds = 100\n",
    "    early_stopping_counter = 0\n",
    "    best_logloss = float('inf')\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    clf = lgb.LGBMClassifier(**params, n_estimators=num_boost_round)\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    val_pred = clf.predict_proba(X_valid, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    logloss = log_loss(y_valid, val_pred)\n",
    "\n",
    "    if logloss < best_logloss:\n",
    "        best_logloss = logloss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_rounds:\n",
    "            return best_logloss  # Early stopping\n",
    "\n",
    "    return best_logloss\n",
    "\n",
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a LightGBM classifier with the best hyperparameters\n",
    "clf = lgb.LGBMClassifier(**best_params, n_estimators=100)  # You can specify a large number of estimators\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=100)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = clf.predict(X_valid)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "# Define pretrainer model architecture\n",
    "pretrainer = TabNetPretrainer(\n",
    "optimizer_fn=torch.optim.Adam,\n",
    "optimizer_params=dict(lr=2e-2),\n",
    "mask_type=\"entmax\"\n",
    ")\n",
    "\n",
    "# Train pretrainer model on training data\n",
    "pretrainer.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_valid],\n",
    "    max_epochs=1000,\n",
    "    patience=30,\n",
    "    pretraining_ratio=0.8,\n",
    "    batch_size= 64\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# Define hyperparameters\n",
    "n_d = 8\n",
    "n_a = 8\n",
    "n_steps = 3\n",
    "gamma = 1\n",
    "lambda_sparse = 0.001\n",
    "lr = 0.0001\n",
    "batch_size = 16\n",
    "max_epochs = 150\n",
    "\n",
    "# Create TabNet classifier\n",
    "clf = TabNetClassifier(n_d=n_d, n_a=n_a, cat_dims=cat,n_steps=n_steps, gamma=gamma, lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=lr), mask_type='entmax', device_name='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Train TabNet classifier\n",
    "clf.fit(X_train=X_train, y_train=y_train,     eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'], eval_metric=['auc','balanced_accuracy'],batch_size=batch_size, max_epochs=max_epochs, patience=0)\n",
    "# from_unsupervised=pickle.load(open('tabnet.pkl', 'rb'))\n",
    "\n",
    "import pickle\n",
    "pickle.dump(clf, open('tabnet.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('tabnet.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(open('tabnet.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(clf.history['loss'], label='Validation Loss')\n",
    "plt.plot(clf.history['valid_auc'], label='AUC')\n",
    "plt.plot(clf.history['valid_balanced_accuracy'], label='Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "r = classification_report(y_pred=y_pred,y_true=y_test)\n",
    "print(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erklärbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = pd.Series(clf.feature_importances_)\n",
    "f_i.index = features\n",
    "f_i.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"BW_opponent_odd_pred\",\"B365_Opponent\",\"Avg_Opponent\",\"IW_Team\",\"Span_Draw\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(f_i>0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss\n",
    "\n",
    "def load_dataset():\n",
    "    # Load your dataset here\n",
    "    # Replace this with your dataset loading code\n",
    "    # X and y should be your feature and target variables\n",
    "    pass\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    shrink_threshold = trial.suggest_float(\"shrink_threshold\", 0.0, 1.0)\n",
    "    \n",
    "    X_train, y_train = get_model_data(filename = \"Train\")\n",
    "    X_valid, y_valid = get_model_data(filename = \"Valid\")\n",
    "    X_test, y_test = get_model_data(filename = \"Test\")\n",
    "    \n",
    "    # Create and train the NearestCentroid classifier with the suggested parameters\n",
    "    clf = NearestCentroid(shrink_threshold=shrink_threshold)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    \n",
    "    # Calculate the accuracy of the model\n",
    "    score = brier_score_loss(y_valid, y_pred)\n",
    "    \n",
    "    return brier_score_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset\n",
    "    \n",
    "    # Specify the SQLite database file for the study\n",
    "    study_name = \"neareast_centroid_optimization.db\"\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=study_name)\n",
    "\n",
    "    # Optimize the study\n",
    "    study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "    # Get the best parameters and their corresponding accuracy\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "\n",
    "    # # Save the study to the specified SQLite database file\n",
    "    # study.trials_dataframe().to_sql(study_name, \"sqlite:///{}\".format(study_name), if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf = NearestCentroid(shrink_threshold=0.95)\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
